{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook explains how to uncover risks related to your usecase based on a given taxonomy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhaval/Projects/Usage-Governance/ai-atlas-nexus/src/ai_atlas_nexus/blocks/risk_explorer/explorer.py:8: UserWarning: Deprecated, Please use AtlasExplorer instead\n",
      "  warnings.warn(\"Deprecated, Please use AtlasExplorer instead\")\n",
      "/Users/dhaval/Projects/Usage-Governance/ai-atlas-nexus/src/ai_atlas_nexus/toolkit/job_utils.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from ai_atlas_nexus.blocks.inference import (\n",
    "    RITSInferenceEngine,\n",
    "    WMLInferenceEngine,\n",
    "    OllamaInferenceEngine,\n",
    "    VLLMInferenceEngine,\n",
    ")\n",
    "from ai_atlas_nexus.blocks.inference.params import (\n",
    "    InferenceEngineCredentials,\n",
    "    RITSInferenceEngineParams,\n",
    "    WMLInferenceEngineParams,\n",
    "    OllamaInferenceEngineParams,\n",
    "    VLLMInferenceEngineParams,\n",
    ")\n",
    "from ai_atlas_nexus.library import AIAtlasNexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AI Atlas Nexus uses Large Language Models (LLMs) to infer risks dimensions. Therefore requires access to LLMs to inference or call the model.\n",
    "\n",
    "**Available Inference Engines**: WML, Ollama, vLLM, RITS. Please follow the [Inference APIs](https://github.com/IBM/ai-atlas-nexus?tab=readme-ov-file#install-for-inference-apis) guide before going ahead.\n",
    "\n",
    "_Note:_ RITS is intended solely for internal IBM use and requires TUNNELALL VPN for access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-16 12:35:55:829] - INFO - AIAtlasNexus - Created RITS inference engine.\n"
     ]
    }
   ],
   "source": [
    "# inference_engine = OllamaInferenceEngine(\n",
    "#     model_name_or_path=\"granite3.3:8b\",\n",
    "#     credentials=InferenceEngineCredentials(api_url=\"OLLAMA_API_URL\"),\n",
    "#     parameters=OllamaInferenceEngineParams(\n",
    "#         num_predict=1000, num_ctx=8192, temperature=0, repeat_penalty=1\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = WMLInferenceEngine(\n",
    "#     model_name_or_path=\"ibm/granite-3-3-8b-instruct\",\n",
    "#     credentials={\n",
    "#         \"api_key\": \"WML_API_KEY\",\n",
    "#         \"api_url\": \"WML_API_URL\",\n",
    "#         \"project_id\": \"WML_PROJECT_ID\",\n",
    "#     },\n",
    "#     parameters=WMLInferenceEngineParams(\n",
    "#         max_new_tokens=1000, decoding_method=\"greedy\", repetition_penalty=1\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = VLLMInferenceEngine(\n",
    "#     model_name_or_path=\"ibm-granite/granite-3.3-8b-instruct\",\n",
    "#     credentials=InferenceEngineCredentials(\n",
    "#         api_url=\"VLLM_API_URL\", api_key=\"VLLM_API_KEY\"\n",
    "#     ),\n",
    "#     parameters=VLLMInferenceEngineParams(max_tokens=1000, temperature=0),\n",
    "# )\n",
    "\n",
    "inference_engine = RITSInferenceEngine(\n",
    "    model_name_or_path=\"ibm-granite/granite-3.3-8b-instruct\",\n",
    "    credentials={\n",
    "        \"api_key\": \"RITS_API_KEY\",\n",
    "        \"api_url\": \"https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com\",\n",
    "    },\n",
    "    parameters=RITSInferenceEngineParams(\n",
    "        max_completion_tokens=1000, temperature=0, logprobs=True, top_logprobs=3\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an instance of AIAtlasNexus\n",
    "\n",
    "_Note: (Optional)_ You can specify your own directory in `AIAtlasNexus(base_dir=<PATH>)` to utilize custom AI ontologies. If left blank, the system will use the provided AI ontologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-16 12:35:56:74] - INFO - AIAtlasNexus - Created AIAtlasNexus instance. Base_dir: None\n"
     ]
    }
   ],
   "source": [
    "ai_atlas_nexus = AIAtlasNexus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Identification API\n",
    "\n",
    "AIAtlasNexus.identify_risks_from_usecases()\n",
    "\n",
    "Params:\n",
    "\n",
    "- usecases (List[str]):\n",
    "  A List of strings describing AI usecases\n",
    "- inference_engine (InferenceEngine):\n",
    "  An LLM inference engine to infer risks from the usecases.\n",
    "- taxonomy (str, optional):\n",
    "  The string label for a taxonomy. Default to None.\n",
    "- cot_examples (Dict[str, List], optional):\n",
    "  The Chain of Thought (CoT) examples to use in the risk identification.\n",
    "  The example template is available at src/ai_atlas_nexus/data/templates/risk_generation_cot.json.\n",
    "  Assign the ID of the taxonomy you wish to use as the key for CoT examples. Providing this value\n",
    "  will override the CoT examples present in the template master. Default to None.\n",
    "- max_risk (int, optional):\n",
    "  The maximum number of risks to extract. Pass None to allow the inference engine to determine the number of risks. Defaults to None.\n",
    "- zero_shot_only (bool): If enabled, this flag allows the system to perform Zero Shot Risk identification, and the field `cot_examples` will be ignored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Identification using IBM AI Risk taxonomy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cca8bd8d8a480387d75ea1728ed1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferring with RITS:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of risks: 2\n",
      "{\n",
      "  \"risk\": \"Hallucination\",\n",
      "  \"explanation\": \"The given AI risk, hallucination, is associated with the use case. The AI model, in this case, is being used to draft a comprehensive section of a government policy report. The task involves understanding and summarizing how Ireland's federal courts have addressed automated penalties in the welfare system. Given the sensitivity and critical nature of the information required for the report, there is a significant risk of hallucination. Hallucination could manifest as the AI generating factually incorrect or ungrounded statements about court decisions, legislation, or the impact of automated decision-making in Ireland's welfare system. This inaccurate information could compromise the report's performance, accuracy, and relevance, potentially leading to flawed policy decisions. Therefore, the risk of hallucination is present in this use case.\"\n",
      "}\n",
      "{\n",
      "  \"risk\": \"Impact on affected communities\",\n",
      "  \"explanation\": \"The given AI Risk, 'Impact on affected communities', is indeed relevant to this use case. The AI system is being used to draft a government policy report on automated decision-making in Ireland's welfare system. This directly impacts the communities receiving welfare benefits in Ireland. If the model fails to consider the perspectives or concerns of these affected communities, it may lead to a policy report that does not adequately address their needs, exacerbates existing inequalities, or erodes trust in the welfare system. Therefore, it's crucial to include these perspectives to ensure the report is fair, accurate, and trustworthy.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "usecase = \"Using AI to write a government policy report on automated decision-making in Ireland's welfare system. The task will include  drafting a comprehensive section analyzing input documents to understand how Ireland federal courts have addressed automated penalties in welfare systems and ensure the output is factually correct.\"\n",
    "\n",
    "risks = ai_atlas_nexus.identify_risks_from_usecases(\n",
    "    usecases=[usecase],\n",
    "    inference_engine=inference_engine,\n",
    "    taxonomy=\"ibm-risk-atlas\",\n",
    "    max_risk=5,\n",
    ")\n",
    "\n",
    "print(\"No. of risks:\", len(risks[0]))\n",
    "for risk in risks[0]:\n",
    "    print(json.dumps(risk, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-nexus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

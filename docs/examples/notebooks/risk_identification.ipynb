{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook explains how to uncover risks related to your usecase based on a given taxonomy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhaval/Projects/Usage-Governance/ai-atlas-nexus/src/ai_atlas_nexus/blocks/risk_explorer/explorer.py:8: UserWarning: Deprecated, Please use AtlasExplorer instead\n",
      "  warnings.warn(\"Deprecated, Please use AtlasExplorer instead\")\n",
      "/Users/dhaval/Projects/Usage-Governance/ai-atlas-nexus/src/ai_atlas_nexus/toolkit/job_utils.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from ai_atlas_nexus.blocks.inference import (\n",
    "    RITSInferenceEngine,\n",
    "    WMLInferenceEngine,\n",
    "    OllamaInferenceEngine,\n",
    "    VLLMInferenceEngine,\n",
    ")\n",
    "from ai_atlas_nexus.blocks.inference.params import (\n",
    "    InferenceEngineCredentials,\n",
    "    RITSInferenceEngineParams,\n",
    "    WMLInferenceEngineParams,\n",
    "    OllamaInferenceEngineParams,\n",
    "    VLLMInferenceEngineParams,\n",
    ")\n",
    "from ai_atlas_nexus.library import AIAtlasNexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AI Atlas Nexus uses Large Language Models (LLMs) to infer risks dimensions. Therefore requires access to LLMs to inference or call the model.\n",
    "\n",
    "**Available Inference Engines**: WML, Ollama, vLLM, RITS. Please follow the [Inference APIs](https://github.com/IBM/ai-atlas-nexus?tab=readme-ov-file#install-for-inference-apis) guide before going ahead.\n",
    "\n",
    "_Note:_ RITS is intended solely for internal IBM use and requires TUNNELALL VPN for access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-16 14:23:43:130] - INFO - AIAtlasNexus - Created RITS inference engine.\n"
     ]
    }
   ],
   "source": [
    "# inference_engine = OllamaInferenceEngine(\n",
    "#     model_name_or_path=\"granite3.3:8b\",\n",
    "#     credentials=InferenceEngineCredentials(api_url=\"OLLAMA_API_URL\"),\n",
    "#     parameters=OllamaInferenceEngineParams(\n",
    "#         num_predict=1000, num_ctx=8192, temperature=0, repeat_penalty=1\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = WMLInferenceEngine(\n",
    "#     model_name_or_path=\"ibm/granite-3-3-8b-instruct\",\n",
    "#     credentials={\n",
    "#         \"api_key\": \"WML_API_KEY\",\n",
    "#         \"api_url\": \"WML_API_URL\",\n",
    "#         \"project_id\": \"WML_PROJECT_ID\",\n",
    "#     },\n",
    "#     parameters=WMLInferenceEngineParams(\n",
    "#         max_new_tokens=1000, decoding_method=\"greedy\", repetition_penalty=1\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = VLLMInferenceEngine(\n",
    "#     model_name_or_path=\"ibm-granite/granite-3.3-8b-instruct\",\n",
    "#     credentials=InferenceEngineCredentials(\n",
    "#         api_url=\"VLLM_API_URL\", api_key=\"VLLM_API_KEY\"\n",
    "#     ),\n",
    "#     parameters=VLLMInferenceEngineParams(max_tokens=1000, temperature=0),\n",
    "# )\n",
    "\n",
    "inference_engine = RITSInferenceEngine(\n",
    "    model_name_or_path=\"ibm-granite/granite-3.3-8b-instruct\",\n",
    "    credentials={\n",
    "        \"api_key\": \"cbc683b3a1a7c52d2a73008b785d2811\",\n",
    "        \"api_url\": \"https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com\",\n",
    "    },\n",
    "    parameters=RITSInferenceEngineParams(\n",
    "        max_completion_tokens=1000, temperature=0, logprobs=True, top_logprobs=3\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an instance of AIAtlasNexus\n",
    "\n",
    "_Note: (Optional)_ You can specify your own directory in `AIAtlasNexus(base_dir=<PATH>)` to utilize custom AI ontologies. If left blank, the system will use the provided AI ontologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-16 14:23:43:383] - INFO - AIAtlasNexus - Created AIAtlasNexus instance. Base_dir: None\n"
     ]
    }
   ],
   "source": [
    "ai_atlas_nexus = AIAtlasNexus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Identification API\n",
    "\n",
    "AIAtlasNexus.identify_risks_from_usecases()\n",
    "\n",
    "Params:\n",
    "\n",
    "- usecases (List[str]):\n",
    "  A List of strings describing AI usecases\n",
    "- inference_engine (InferenceEngine):\n",
    "  An LLM inference engine to infer risks from the usecases.\n",
    "- taxonomy (str, optional):\n",
    "  The string label for a taxonomy. Default to None.\n",
    "- cot_examples (Dict[str, List], optional):\n",
    "  The Chain of Thought (CoT) examples to use in the risk identification.\n",
    "  The example template is available at src/ai_atlas_nexus/data/templates/risk_generation_cot.json.\n",
    "  Assign the ID of the taxonomy you wish to use as the key for CoT examples. Providing this value\n",
    "  will override the CoT examples present in the template master. Default to None.\n",
    "- max_risk (int, optional):\n",
    "  The maximum number of risks to extract. Pass None to allow the inference engine to determine the number of risks. Defaults to None.\n",
    "- zero_shot_only (bool): If enabled, this flag allows the system to perform Zero Shot Risk identification, and the field `cot_examples` will be ignored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase = \"Using AI to write a government policy report on automated decision-making in Ireland's welfare system. The task will include  drafting a comprehensive section analyzing input documents to understand how Ireland federal courts have addressed automated penalties in welfare systems and ensure the output is factually correct.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Identification using IBM AI Risk taxonomy - Batch Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d22ae0c03df48e7b3b57fa11674fbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferring with RITS:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of risks: 5\n",
      "Incorrect risk testing\n",
      "Over- or under-reliance\n",
      "Discriminatory actions\n",
      "Harmful output\n",
      "Lack of model transparency\n"
     ]
    }
   ],
   "source": [
    "risks = ai_atlas_nexus.identify_risks_from_usecases(\n",
    "    usecases=[usecase],\n",
    "    inference_engine=inference_engine,\n",
    "    taxonomy=\"ibm-risk-atlas\",\n",
    "    max_risk=5,\n",
    "    batch_inference=True,\n",
    ")\n",
    "\n",
    "print(\"No. of risks:\", len(risks[0]))\n",
    "for risk in risks[0]:\n",
    "    print(risk.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Identification using IBM AI Risk taxonomy - Inference per risk level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426b577ed52d436ca68211fbce70259e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferring with RITS:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of risks: 2\n",
      "Hallucination\n",
      "Impact on affected communities\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "risks = ai_atlas_nexus.identify_risks_from_usecases(\n",
    "    usecases=[usecase],\n",
    "    inference_engine=inference_engine,\n",
    "    taxonomy=\"ibm-risk-atlas\",\n",
    "    batch_inference=False,\n",
    ")\n",
    "\n",
    "print(\"No. of risks:\", len(risks[0]))\n",
    "for risk in risks[0]:\n",
    "    print(risk.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-nexus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
